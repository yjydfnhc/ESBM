# ESBM Benchmark v1.0 (Last update: 2018-07-27)
https://w3id.org/esbm/1.0 

License: [ODC Attribution License (ODC-By)](https://opendatacommons.org/licenses/by/1-0/index.html)

ESBM (short for Entity Summarization BenchMark) is a benchmark for evaluating algorithms for entity summarization, aka entity summarizers.


# Download

* ESBM_benchmark: data of ESBM;
* Evaluator (jar, src): executable package and example code of the evaluator;
* summ_example: example of output files generated by an entity summarizer to be evaluated;
* runs: output files generated by selected entity summarizers.

# Data

The ESBM benchmark consists of 140 entities (see elist.txt) selected from [DBpedia](http://wiki.dbpedia.org/dbpedia-dataset-version-2015-10) and (LinkedMDB)[http://www.cs.toronto.edu/~oktie/linkedmdb/linkedmdb-latest-dump.zip]. For each entity, we provide its original description to be summarized and its gold-standard summaries created by crowdsourcing, all available as N-Triples documents.

* <code>desc</code>: entity description to be summarized;
* <code>top5</code>: six gold-standard summaries independently created by different people under <strong>k=5</strong> (i.e., 5 triples in each summary);
* <code>top10</code>: six gold-standard summaries independently created by different people under <strong>k=10</strong> (i.e., 10 triples in each summary).
The directory structure of these files is as follows.

<pre>|--ESBM_benchmark
	|-- dbpedia
		|-- 1
			|-- 1_desc.nt
			|-- 1_gold_top5_0.nt
			|-- 1_gold_top5_1.nt
			|-- ...
			|-- 1_gold_top5_5.nt
			|-- 1_gold_top10_0.nt
			|-- 1_gold_top10_1.nt
			|-- ...
			|-- 1_gold_top10_0.nt
		|-- 2
		|-- ...
		|-- 100
  	|-- lmdb
		|-- 101
			|-- 101_desc.nt
			|-- 101_gold_top5_0.nt
			|-- ...
		|-- 102
		|-- ...
		|-- 140
</pre>

# Evaluation

An evaluator written in Java is provided for evaluating your own entity summarizer based on the ESBM benchmark.

## Required Output Format

Summaries generated by your entity summarizer to be evaluated should be outputted also as N-Triples documents (see OutputExample.java in src). For each entity, provide the following output files generated by your entity summarizer.

* <code>top5</code>: summary generated by your entity summarizer under <strong>k=5</strong>;
* <code>top10</code>: summary generated by your entity summarizer under <strong>k=10</strong>;
* <code>rank</code>: ranked list of all the triples in the entity description. This file is optional. Provide it only if your entity summarizer is capable of generating a ranking of all the triples, so that our evaluator can report its MAP score.
The directory structure of these files should be as follows.

<pre>|--summ_example
	|-- dbpedia
		|-- 1
			|-- 1_top5.nt
			|-- 1_top10.nt
			|-- 1_rank.nt
		|-- 2
		|-- ...
		|-- 100
  	|-- lmdb
		|-- 101
			|-- 101_top5.nt
			|-- 101_top10.nt
			|-- 101_rank.nt
		|-- 102
		|-- ...
		|-- 140
</pre>

An example of output files is given in <code>summ_example</code>.

## Run the Evaluator

Unzip the benchmark data before running the evaluator.

The evaluator receives two arguments:

Path of the benchmark data, e.g. <code>/home/user/eval/ESBM_benchmark/</code>
Path of the output files generated by your entity summarizer, e.g. <code>/home/user/eval/summ_example/</code>
Run the evaluator (jar) using the following command (Java 8 is required):

<pre>$ java -jar esummeval_v1.0.jar /home/user/eval/ESBM_benchmark_v1.0/ /home/user/eval/summ_example/
</pre>

Output of the evaluator will look like:


<pre>******************************************
Evaluating with settings:
 benchmark directory: /home/user/eval/ESBM_benchmark/
 summarizer output directory: /home/user/eval/summ_example/

=================
Dataset: dbpedia
Results(dbpedia@top5):  F-measure=0.24999999999999997, MAP=0.34814702465126496
Results(dbpedia@top10): F-measure=0.46833333333333316, MAP=0.5317130048624622
=================
Dataset: lmdb
Results(lmdb@top5):     F-measure=0.20999999999999996, MAP=0.2433344674280165
Results(lmdb@top10):    F-measure=0.25958333333333333, MAP=0.336726885240028
=================
For all 140 entities:
Results(all@top5):      F-measure=0.23857142857142852, MAP=0.31820057973033683
Results(all@top10):     F-measure=0.40869047619047605, MAP=0.47600268497033815
</pre>

<p>Results for <code>dbpedia</code>, <code>lmdb</code> and <code>all</code> are averaged over 100, 40, and 140 entities, respectively, even if your entity summarizer does not provide summaries for all the entities.</p>


# Contact
If you have any questions or suggestions, please feel free to contact [Qingxia Liu](http://ws.nju.edu.cn/people/qxliu) and [Gong Cheng](http://ws.nju.edu.cn/~gcheng). This work is also credited to Kalpa Gunaratna.
